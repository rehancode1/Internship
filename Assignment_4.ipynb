{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91fe97a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a2aa66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>12.73</td>\n",
       "      <td>June 17 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.14</td>\n",
       "      <td>January 12 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>6.69</td>\n",
       "      <td>October 8 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[15]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>6.15</td>\n",
       "      <td>May 2 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[16]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.97</td>\n",
       "      <td>January 30 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.86</td>\n",
       "      <td>April 6 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[23]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>5.26</td>\n",
       "      <td>March 6 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"[24]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>5.14</td>\n",
       "      <td>May 24 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[25]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.89</td>\n",
       "      <td>November 19 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[26]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.87</td>\n",
       "      <td>February 27 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.77</td>\n",
       "      <td>July 15 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[32]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.55</td>\n",
       "      <td>January 31 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[33]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>4.32</td>\n",
       "      <td>April 5 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[34]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>3.87</td>\n",
       "      <td>June 16 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[35]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.86</td>\n",
       "      <td>January 14 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"[36]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.78</td>\n",
       "      <td>September 5 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"[37]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.77</td>\n",
       "      <td>May 31 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.65</td>\n",
       "      <td>October 22 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[39]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.61</td>\n",
       "      <td>June 25 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Thinking Out Loud\"[40]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.58</td>\n",
       "      <td>October 7 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[41]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.56</td>\n",
       "      <td>June 4 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"[42]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.50</td>\n",
       "      <td>February 20 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Faded\"[43]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.44</td>\n",
       "      <td>December 3 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Perfect\"[44]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.42</td>\n",
       "      <td>November 9 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[45]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.42</td>\n",
       "      <td>June 14 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[46]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.42</td>\n",
       "      <td>July 25 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Girls Like You\"[47]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.40</td>\n",
       "      <td>May 31 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.38</td>\n",
       "      <td>January 26 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Lean On\"[49]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.37</td>\n",
       "      <td>March 22 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Bailando\"[50]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.37</td>\n",
       "      <td>April 11 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[4]   \n",
       "1    2.                                   \"Despacito\"[7]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[14]   \n",
       "3    4.                                  \"Bath Song\"[15]   \n",
       "4    5.                               \"Shape of You\"[16]   \n",
       "5    6.                              \"See You Again\"[18]   \n",
       "6    7.                \"Phonics Song with Two Words\"[23]   \n",
       "7    8.                          \"Wheels on the Bus\"[24]   \n",
       "8    9.                                \"Uptown Funk\"[25]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[26]   \n",
       "10  11.                              \"Gangnam Style\"[27]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[32]   \n",
       "12  13.                             \"Dame Tu Cosita\"[33]   \n",
       "13  14.                                     \"Axel F\"[34]   \n",
       "14  15.                                      \"Sugar\"[35]   \n",
       "15  16.                                       \"Roar\"[36]   \n",
       "16  17.                             \"Counting Stars\"[37]   \n",
       "17  18.                                      \"Sorry\"[38]   \n",
       "18  19.                        \"Baa Baa Black Sheep\"[39]   \n",
       "19  20.                          \"Thinking Out Loud\"[40]   \n",
       "20  21.           \"Waka Waka (This Time for Africa)\"[41]   \n",
       "21  22.                                 \"Dark Horse\"[42]   \n",
       "22  23.                                      \"Faded\"[43]   \n",
       "23  24.                                    \"Perfect\"[44]   \n",
       "24  25.                             \"Lakdi Ki Kathi\"[45]   \n",
       "25  26.                                 \"Let Her Go\"[46]   \n",
       "26  27.                             \"Girls Like You\"[47]   \n",
       "27  28.          \"Humpty the train on a fruits ride\"[48]   \n",
       "28  29.                                    \"Lean On\"[49]   \n",
       "29  30.                                   \"Bailando\"[50]   \n",
       "\n",
       "                                           Artist Rating       Upload Date  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories  12.73      June 17 2016  \n",
       "1                                      Luis Fonsi   8.14   January 12 2017  \n",
       "2                                     LooLoo Kids   6.69    October 8 2016  \n",
       "3                      Cocomelon – Nursery Rhymes   6.15        May 2 2018  \n",
       "4                                      Ed Sheeran   5.97   January 30 2017  \n",
       "5                                     Wiz Khalifa   5.86      April 6 2015  \n",
       "6                                       ChuChu TV   5.26      March 6 2014  \n",
       "7                      Cocomelon – Nursery Rhymes   5.14       May 24 2018  \n",
       "8                                     Mark Ronson   4.89  November 19 2014  \n",
       "9                                     Miroshka TV   4.87  February 27 2018  \n",
       "10                                            Psy   4.77      July 15 2012  \n",
       "11                                     Get Movies   4.55   January 31 2012  \n",
       "12                                      El Chombo   4.32      April 5 2018  \n",
       "13                                     Crazy Frog   3.87      June 16 2009  \n",
       "14                                       Maroon 5   3.86   January 14 2015  \n",
       "15                                     Katy Perry   3.78  September 5 2013  \n",
       "16                                    OneRepublic   3.77       May 31 2013  \n",
       "17                                  Justin Bieber   3.65   October 22 2015  \n",
       "18                     Cocomelon – Nursery Rhymes   3.61      June 25 2018  \n",
       "19                                     Ed Sheeran   3.58    October 7 2014  \n",
       "20                                        Shakira   3.56       June 4 2010  \n",
       "21                                     Katy Perry   3.50  February 20 2014  \n",
       "22                                    Alan Walker   3.44   December 3 2015  \n",
       "23                                     Ed Sheeran   3.42   November 9 2017  \n",
       "24                                   Jingle Toons   3.42      June 14 2018  \n",
       "25                                      Passenger   3.42      July 25 2012  \n",
       "26                                       Maroon 5   3.40       May 31 2018  \n",
       "27  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   3.38   January 26 2018  \n",
       "28                                    Major Lazer   3.37     March 22 2015  \n",
       "29                               Enrique Iglesias   3.37     April 11 2014  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer No.1\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "table = soup.find(\"table\", class_=\"wikitable sortable\")\n",
    "rows = table.find_all(\"tr\")[1:]\n",
    "\n",
    "data = []\n",
    "for row in rows:\n",
    "    cols = row.find_all(\"td\")\n",
    "    if len(cols) > 0:\n",
    "        rank = cols[0].text.strip()\n",
    "        name = cols[1].text.strip()\n",
    "        artist = cols[2].text.strip()\n",
    "        upload_date = cols[3].text.strip()\n",
    "        views = cols[4].text.strip().replace(\",\", \"\")\n",
    "        data.append([rank, name, artist, upload_date, views])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Rank\", \"Name\", \"Artist\", \"Rating\", \"Upload Date\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03fb2360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>2011–2019</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,154,096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>2016–2024</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,235,995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>2010–2022</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,023,293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>2017–2020</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>301,129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>2014–2020</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>260,060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>2013–2017</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>51,406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>2017–2019</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>63,448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>2005–</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>206,886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream</td>\n",
       "      <td>2015–2019</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>42,954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>2018</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>256,563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name  Year Span                     Genre  \\\n",
       "0                  Game of Thrones  2011–2019  Action, Adventure, Drama   \n",
       "1                  Stranger Things  2016–2024    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  2010–2022   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  2017–2020  Drama, Mystery, Thriller   \n",
       "4                          The 100  2014–2020    Drama, Mystery, Sci-Fi   \n",
       "..                             ...        ...                       ...   \n",
       "95                           Reign  2013–2017                     Drama   \n",
       "96  A Series of Unfortunate Events  2017–2019  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     2005–      Crime, Drama, Mystery   \n",
       "98                          Scream  2015–2019      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       2018    Drama, Horror, Mystery   \n",
       "\n",
       "    Runtime Rating      Votes  \n",
       "0    57 min    9.2  2,154,096  \n",
       "1    51 min    8.7  1,235,995  \n",
       "2    44 min    8.1  1,023,293  \n",
       "3    60 min    7.5    301,129  \n",
       "4    43 min    7.6    260,060  \n",
       "..      ...    ...        ...  \n",
       "95   42 min    7.4     51,406  \n",
       "96   50 min    7.8     63,448  \n",
       "97   42 min    8.1    206,886  \n",
       "98   45 min      7     42,954  \n",
       "99  572 min    8.6    256,563  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.imdb.com/list/ls095964455/'\n",
    "\n",
    "# Send a request to the webpage\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse HTML content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all the TV series listed\n",
    "series_list = soup.find_all('div', {'class': 'lister-item mode-detail'})\n",
    "\n",
    "# Create empty lists to store the details\n",
    "names = []\n",
    "year_spans = []\n",
    "genres = []\n",
    "runtimes = []\n",
    "ratings = []\n",
    "votes = []\n",
    "\n",
    "# Loop through each TV series and extract the details\n",
    "for series in series_list:\n",
    "    name = series.h3.a.text.strip()\n",
    "    names.append(name)\n",
    "    \n",
    "    year_span = series.find('span', {'class': 'lister-item-year'}).text.strip('()')\n",
    "    year_spans.append(year_span)\n",
    "    \n",
    "    genre = series.find('span', {'class': 'genre'}).text.strip()\n",
    "    genres.append(genre)\n",
    "    \n",
    "    runtime = series.find('span', {'class': 'runtime'}).text.strip()\n",
    "    runtimes.append(runtime)\n",
    "    \n",
    "    rating = series.find('div', {'class': 'ipl-rating-star small'}).text.strip()\n",
    "    ratings.append(rating)\n",
    "    \n",
    "    vote = series.find('span', {'name': 'nv'}).text.strip()\n",
    "    votes.append(vote)\n",
    "\n",
    "data_dict = {\n",
    "    'Name': names,\n",
    "    'Year Span': year_spans,\n",
    "    'Genre': genres,\n",
    "    'Runtime': runtimes,\n",
    "    'Rating': ratings,\n",
    "    'Votes' : votes\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfb17ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>No of Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Center for Machine Learning and Intelligent Sy...</td>\n",
       "      <td>About  Citation Policy  Donate a Data Set  Con...</td>\n",
       "      <td>Welcome to the UC Irvine Machine Learning Repo...</td>\n",
       "      <td>Supported By:</td>\n",
       "      <td></td>\n",
       "      <td>In Collaboration With:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Center for Machine Learning and Intelligent Sy...</td>\n",
       "      <td>About  Citation Policy  Donate a Data Set  Con...</td>\n",
       "      <td>Welcome to the UC Irvine Machine Learning Repo...</td>\n",
       "      <td>Supported By:</td>\n",
       "      <td></td>\n",
       "      <td>In Collaboration With:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Center for Machine Learning and Intelligent Sy...</td>\n",
       "      <td>About  Citation Policy  Donate a Data Set  Con...</td>\n",
       "      <td>Welcome to the UC Irvine Machine Learning Repo...</td>\n",
       "      <td>Supported By:</td>\n",
       "      <td></td>\n",
       "      <td>In Collaboration With:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Center for Machine Learning and Intelligent Sy...</td>\n",
       "      <td>About  Citation Policy  Donate a Data Set  Con...</td>\n",
       "      <td>Welcome to the UC Irvine Machine Learning Repo...</td>\n",
       "      <td>Supported By:</td>\n",
       "      <td></td>\n",
       "      <td>In Collaboration With:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Center for Machine Learning and Intelligent Sy...</td>\n",
       "      <td>About  Citation Policy  Donate a Data Set  Con...</td>\n",
       "      <td>Welcome to the UC Irvine Machine Learning Repo...</td>\n",
       "      <td>Supported By:</td>\n",
       "      <td></td>\n",
       "      <td>In Collaboration With:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Center for Machine Learning and Intelligent Sy...</td>\n",
       "      <td>About  Citation Policy  Donate a Data Set  Con...</td>\n",
       "      <td>Welcome to the UC Irvine Machine Learning Repo...</td>\n",
       "      <td>Supported By:</td>\n",
       "      <td></td>\n",
       "      <td>In Collaboration With:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Center for Machine Learning and Intelligent Sy...</td>\n",
       "      <td>About  Citation Policy  Donate a Data Set  Con...</td>\n",
       "      <td>Welcome to the UC Irvine Machine Learning Repo...</td>\n",
       "      <td>Supported By:</td>\n",
       "      <td></td>\n",
       "      <td>In Collaboration With:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Center for Machine Learning and Intelligent Sy...</td>\n",
       "      <td>About  Citation Policy  Donate a Data Set  Con...</td>\n",
       "      <td>Welcome to the UC Irvine Machine Learning Repo...</td>\n",
       "      <td>Supported By:</td>\n",
       "      <td></td>\n",
       "      <td>In Collaboration With:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Center for Machine Learning and Intelligent Sy...</td>\n",
       "      <td>About  Citation Policy  Donate a Data Set  Con...</td>\n",
       "      <td>Welcome to the UC Irvine Machine Learning Repo...</td>\n",
       "      <td>Supported By:</td>\n",
       "      <td></td>\n",
       "      <td>In Collaboration With:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Center for Machine Learning and Intelligent Sy...</td>\n",
       "      <td>About  Citation Policy  Donate a Data Set  Con...</td>\n",
       "      <td>Welcome to the UC Irvine Machine Learning Repo...</td>\n",
       "      <td>Supported By:</td>\n",
       "      <td></td>\n",
       "      <td>In Collaboration With:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Dataset Name  \\\n",
       "0   Center for Machine Learning and Intelligent Sy...   \n",
       "1   Center for Machine Learning and Intelligent Sy...   \n",
       "2   Center for Machine Learning and Intelligent Sy...   \n",
       "3   Center for Machine Learning and Intelligent Sy...   \n",
       "4   Center for Machine Learning and Intelligent Sy...   \n",
       "..                                                ...   \n",
       "58  Center for Machine Learning and Intelligent Sy...   \n",
       "59  Center for Machine Learning and Intelligent Sy...   \n",
       "60  Center for Machine Learning and Intelligent Sy...   \n",
       "61  Center for Machine Learning and Intelligent Sy...   \n",
       "62  Center for Machine Learning and Intelligent Sy...   \n",
       "\n",
       "                                            Data Type  \\\n",
       "0   About  Citation Policy  Donate a Data Set  Con...   \n",
       "1   About  Citation Policy  Donate a Data Set  Con...   \n",
       "2   About  Citation Policy  Donate a Data Set  Con...   \n",
       "3   About  Citation Policy  Donate a Data Set  Con...   \n",
       "4   About  Citation Policy  Donate a Data Set  Con...   \n",
       "..                                                ...   \n",
       "58  About  Citation Policy  Donate a Data Set  Con...   \n",
       "59  About  Citation Policy  Donate a Data Set  Con...   \n",
       "60  About  Citation Policy  Donate a Data Set  Con...   \n",
       "61  About  Citation Policy  Donate a Data Set  Con...   \n",
       "62  About  Citation Policy  Donate a Data Set  Con...   \n",
       "\n",
       "                                                 Task Attribute Type  \\\n",
       "0   Welcome to the UC Irvine Machine Learning Repo...  Supported By:   \n",
       "1   Welcome to the UC Irvine Machine Learning Repo...  Supported By:   \n",
       "2   Welcome to the UC Irvine Machine Learning Repo...  Supported By:   \n",
       "3   Welcome to the UC Irvine Machine Learning Repo...  Supported By:   \n",
       "4   Welcome to the UC Irvine Machine Learning Repo...  Supported By:   \n",
       "..                                                ...            ...   \n",
       "58  Welcome to the UC Irvine Machine Learning Repo...  Supported By:   \n",
       "59  Welcome to the UC Irvine Machine Learning Repo...  Supported By:   \n",
       "60  Welcome to the UC Irvine Machine Learning Repo...  Supported By:   \n",
       "61  Welcome to the UC Irvine Machine Learning Repo...  Supported By:   \n",
       "62  Welcome to the UC Irvine Machine Learning Repo...  Supported By:   \n",
       "\n",
       "   No of Instances        No of Attributes Year  \n",
       "0                   In Collaboration With:       \n",
       "1                   In Collaboration With:       \n",
       "2                   In Collaboration With:       \n",
       "3                   In Collaboration With:       \n",
       "4                   In Collaboration With:       \n",
       "..             ...                     ...  ...  \n",
       "58                  In Collaboration With:       \n",
       "59                  In Collaboration With:       \n",
       "60                  In Collaboration With:       \n",
       "61                  In Collaboration With:       \n",
       "62                  In Collaboration With:       \n",
       "\n",
       "[63 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\rehan\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(url)\n",
    "time.sleep(10)\n",
    "\n",
    "table = driver.find_elements(By.XPATH, \"//table\")[5]\n",
    "rows = table.find_elements(By.XPATH, \"//tr\")[1:]\n",
    "\n",
    "data = []\n",
    "for row in rows:\n",
    "    cols = row.find_elements(By.XPATH, \"//td\")\n",
    "    name = cols[0].text.strip()\n",
    "    data_type = cols[1].text.strip()\n",
    "    task = cols[2].text.strip()\n",
    "    attribute_type = cols[3].text.strip()\n",
    "    instances = cols[4].text.strip()\n",
    "    attributes = cols[5].text.strip()\n",
    "    year = cols[6].text.strip()\n",
    "    data.append([name, data_type, task, attribute_type, instances, attributes, year])\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Dataset Name', 'Data Type', 'Task', 'Attribute Type', 'No of Instances', 'No of Attributes', 'Year'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e837953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the link to the international fixtures page.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Send a GET request to the BCCI website\n",
    "url = 'https://www.bcci.tv/'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the link to the international fixtures page\n",
    "fixtures_link = soup.find('a', {'class': 'navigation__link', 'title': 'Fixtures'})\n",
    "\n",
    "if fixtures_link is not None:\n",
    "    fixtures_link = fixtures_link.get('href')\n",
    "    fixtures_url = 'https://www.bcci.tv' + fixtures_link\n",
    "\n",
    "    # Send a GET request to the international fixtures page\n",
    "    response = requests.get(fixtures_url)\n",
    "\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all the fixtures on the page\n",
    "    fixtures = soup.find_all('div', {'class': 'js-list'})\n",
    "\n",
    "    # Loop through each fixture and extract the details\n",
    "    for fixture in fixtures:\n",
    "        title = fixture.find('p', {'class': 'fixture__additional-info'}).text.strip()\n",
    "        series = fixture.find('span', {'class': 'u-unskewed-text'}).text.strip()\n",
    "        place = fixture.find('p', {'class': 'fixture__additional-info'}).find_next_sibling('span').text.strip()\n",
    "        date_time = fixture.find('div', {'class': 'fixture__datetime desktop-only'}).text.strip()\n",
    "\n",
    "        # Print the details of the fixture\n",
    "        print('Title:', title)\n",
    "        print('Series:', series)\n",
    "        print('Place:', place)\n",
    "        print('Date and Time:', date_time)\n",
    "        print('-' * 50)\n",
    "else:\n",
    "    print('Could not find the link to the international fixtures page.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36f52752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Song, Artist, Last Week Rank, Peak Rank, Weeks on Board]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website to be scraped\n",
    "url = 'https://www.billboard.com/charts/hot-100'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the table containing the top 100 songs\n",
    "table = soup.find('div', {'class': \"a-span2 lrv-u-padding-r-2 lrv-u-padding-r-00@mobile-max lrv-u-height-100p\"})\n",
    "\n",
    "# Create empty lists to store the song details\n",
    "song_names = []\n",
    "artist_names = []\n",
    "last_week_ranks = []\n",
    "peak_ranks = []\n",
    "weeks_on_board = []\n",
    "\n",
    "# Extract the details of each song from the table\n",
    "for row in table.find_all('tr'):\n",
    "    # Extract the song name\n",
    "    song_name = row.find('span', {'class': 'chart-element__information__song'}).text\n",
    "    song_names.append(song_name)\n",
    "    \n",
    "    # Extract the artist name\n",
    "    artist_name = row.find('span', {'class': 'chart-element__information__artist'}).text\n",
    "    artist_names.append(artist_name)\n",
    "    \n",
    "    # Extract the last week rank\n",
    "    last_week_rank = row.find('span', {'class': 'chart-element__meta text--center color--secondary text--last'}).text\n",
    "    last_week_ranks.append(last_week_rank)\n",
    "    \n",
    "    # Extract the peak rank\n",
    "    peak_rank = row.find('span', {'class': 'chart-element__meta text--center color--secondary text--peak'}).text\n",
    "    peak_ranks.append(peak_rank)\n",
    "    \n",
    "    # Extract the weeks on board\n",
    "    weeks_on_board = row.find('span', {'class': 'chart-element__meta text--center color--secondary text--week'}).text\n",
    "    weeks_on_board.append(weeks_on_board)\n",
    "\n",
    "# Create a dataframe from the lists of song details\n",
    "songs_df = pd.DataFrame({\n",
    "    'Song': song_names,\n",
    "    'Artist': artist_names,\n",
    "    'Last Week Rank': last_week_ranks,\n",
    "    'Peak Rank': peak_ranks,\n",
    "    'Weeks on Board': weeks_on_board\n",
    "})\n",
    "\n",
    "# Print the dataframe\n",
    "print(songs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3595094b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
