{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0be5bcb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main Page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Welcome to Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Header\n",
       "0                      Main Page\n",
       "1           Welcome to Wikipedia\n",
       "2  From today's featured article\n",
       "3               Did you know ...\n",
       "4                    In the news\n",
       "5                    On this day\n",
       "6       Today's featured picture\n",
       "7       Other areas of Wikipedia\n",
       "8    Wikipedia's sister projects\n",
       "9            Wikipedia languages"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Answer no.1\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Main_Page\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "headers = [header.text.strip() for header in soup.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"])]\n",
    "\n",
    "df = pd.DataFrame(headers, columns=[\"Header\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1b09863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>None</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>None</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>None</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>None</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>None</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>None</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>None</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>None</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Lord of the Rings: The Fellowship of the Ring</td>\n",
       "      <td>None</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Il buono, il brutto, il cattivo</td>\n",
       "      <td>None</td>\n",
       "      <td>1966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>None</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>None</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Lord of the Rings: The Two Towers</td>\n",
       "      <td>None</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Inception</td>\n",
       "      <td>None</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Empire Strikes Back</td>\n",
       "      <td>None</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Matrix</td>\n",
       "      <td>None</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GoodFellas</td>\n",
       "      <td>None</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>None</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Se7en</td>\n",
       "      <td>None</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Shichinin no samurai</td>\n",
       "      <td>None</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>It's a Wonderful Life</td>\n",
       "      <td>None</td>\n",
       "      <td>1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>The Silence of the Lambs</td>\n",
       "      <td>None</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Saving Private Ryan</td>\n",
       "      <td>None</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cidade de Deus</td>\n",
       "      <td>None</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>None</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>La vita è bella</td>\n",
       "      <td>None</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The Green Mile</td>\n",
       "      <td>None</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Star Wars</td>\n",
       "      <td>None</td>\n",
       "      <td>1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Terminator 2: Judgment Day</td>\n",
       "      <td>None</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Back to the Future</td>\n",
       "      <td>None</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Sen to Chihiro no kamikakushi</td>\n",
       "      <td>None</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>The Pianist</td>\n",
       "      <td>None</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Psycho</td>\n",
       "      <td>None</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Gisaengchung</td>\n",
       "      <td>None</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Léon</td>\n",
       "      <td>None</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>The Lion King</td>\n",
       "      <td>None</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Gladiator</td>\n",
       "      <td>None</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>American History X</td>\n",
       "      <td>None</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>The Departed</td>\n",
       "      <td>None</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>The Prestige</td>\n",
       "      <td>None</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Whiplash</td>\n",
       "      <td>None</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>The Usual Suspects</td>\n",
       "      <td>None</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Casablanca</td>\n",
       "      <td>None</td>\n",
       "      <td>1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Hotaru no haka</td>\n",
       "      <td>None</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Seppuku</td>\n",
       "      <td>None</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>The Intouchables</td>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Modern Times</td>\n",
       "      <td>None</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Once Upon a Time in the West</td>\n",
       "      <td>None</td>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Nuovo Cinema Paradiso</td>\n",
       "      <td>None</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rear Window</td>\n",
       "      <td>None</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name Rating  Year\n",
       "0                            The Shawshank Redemption   None  1994\n",
       "1                                       The Godfather   None  1972\n",
       "2                                     The Dark Knight   None  2008\n",
       "3                               The Godfather Part II   None  1974\n",
       "4                                        12 Angry Men   None  1957\n",
       "5                                    Schindler's List   None  1993\n",
       "6       The Lord of the Rings: The Return of the King   None  2003\n",
       "7                                        Pulp Fiction   None  1994\n",
       "8   The Lord of the Rings: The Fellowship of the Ring   None  2001\n",
       "9                     Il buono, il brutto, il cattivo   None  1966\n",
       "10                                       Forrest Gump   None  1994\n",
       "11                                         Fight Club   None  1999\n",
       "12              The Lord of the Rings: The Two Towers   None  2002\n",
       "13                                          Inception   None  2010\n",
       "14                            The Empire Strikes Back   None  1980\n",
       "15                                         The Matrix   None  1999\n",
       "16                                         GoodFellas   None  1990\n",
       "17                    One Flew Over the Cuckoo's Nest   None  1975\n",
       "18                                              Se7en   None  1995\n",
       "19                               Shichinin no samurai   None  1954\n",
       "20                              It's a Wonderful Life   None  1946\n",
       "21                           The Silence of the Lambs   None  1991\n",
       "22                                Saving Private Ryan   None  1998\n",
       "23                                     Cidade de Deus   None  2002\n",
       "24                                       Interstellar   None  2014\n",
       "25                                    La vita è bella   None  1997\n",
       "26                                     The Green Mile   None  1999\n",
       "27                                          Star Wars   None  1977\n",
       "28                         Terminator 2: Judgment Day   None  1991\n",
       "29                                 Back to the Future   None  1985\n",
       "30                      Sen to Chihiro no kamikakushi   None  2001\n",
       "31                                        The Pianist   None  2002\n",
       "32                                             Psycho   None  1960\n",
       "33                                       Gisaengchung   None  2019\n",
       "34                                               Léon   None  1994\n",
       "35                                      The Lion King   None  1994\n",
       "36                                          Gladiator   None  2000\n",
       "37                                 American History X   None  1998\n",
       "38                                       The Departed   None  2006\n",
       "39                                       The Prestige   None  2006\n",
       "40                                           Whiplash   None  2014\n",
       "41                                 The Usual Suspects   None  1995\n",
       "42                                         Casablanca   None  1942\n",
       "43                                     Hotaru no haka   None  1988\n",
       "44                                            Seppuku   None  1962\n",
       "45                                   The Intouchables   None  2011\n",
       "46                                       Modern Times   None  1936\n",
       "47                       Once Upon a Time in the West   None  1968\n",
       "48                              Nuovo Cinema Paradiso   None  1988\n",
       "49                                        Rear Window   None  1954"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL to scrape IMDB's Top Rated 50 movies\n",
    "url = 'https://www.imdb.com/chart/top/'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the movie data in the HTML content\n",
    "movie_data = soup.select('td.titleColumn')\n",
    "\n",
    "# Initialize lists to store movie data\n",
    "names = []\n",
    "ratings = []\n",
    "years = []\n",
    "\n",
    "# Loop through each movie's data and extract the name, rating, and year\n",
    "for movie in movie_data:\n",
    "    name = movie.a.text\n",
    "    rating = movie.strong\n",
    "    year = movie.span.text.strip('()')\n",
    "    names.append(name)\n",
    "    ratings.append(rating)\n",
    "    years.append(year)\n",
    "\n",
    "# Create a dictionary to store the movie data\n",
    "movie_dict = {'Name': names, 'Rating': ratings, 'Year': years}\n",
    "\n",
    "# Create a pandas data frame from the dictionary\n",
    "movie_df = pd.DataFrame(movie_dict)\n",
    "\n",
    "# Print the data frame\n",
    "movie_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c6dbcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ramayana: The Legend of Prince Rama</td>\n",
       "      <td>None</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rocketry: The Nambi Effect</td>\n",
       "      <td>None</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>None</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gol Maal</td>\n",
       "      <td>None</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>777 Charlie</td>\n",
       "      <td>None</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>None</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>None</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jai Bhim</td>\n",
       "      <td>None</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Apur Sansar</td>\n",
       "      <td>None</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>None</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Manichitrathazhu</td>\n",
       "      <td>None</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>#Home</td>\n",
       "      <td>None</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Soorarai Pottru</td>\n",
       "      <td>None</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Black Friday</td>\n",
       "      <td>None</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kumbalangi Nights</td>\n",
       "      <td>None</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C/o Kancharapalem</td>\n",
       "      <td>None</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Taare Zameen Par</td>\n",
       "      <td>None</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kireedam</td>\n",
       "      <td>None</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dangal</td>\n",
       "      <td>None</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kaithi</td>\n",
       "      <td>None</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Jersey</td>\n",
       "      <td>None</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>96</td>\n",
       "      <td>None</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Maya Bazaar</td>\n",
       "      <td>None</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Natsamrat</td>\n",
       "      <td>None</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Drishyam 2</td>\n",
       "      <td>None</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Asuran</td>\n",
       "      <td>None</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sita Ramam</td>\n",
       "      <td>None</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Thevar Magan</td>\n",
       "      <td>None</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Visaaranai</td>\n",
       "      <td>None</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sarpatta Parambarai</td>\n",
       "      <td>None</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Thalapathi</td>\n",
       "      <td>None</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Nadodikkattu</td>\n",
       "      <td>None</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Pather Panchali</td>\n",
       "      <td>None</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Drishyam</td>\n",
       "      <td>None</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Thani Oruvan</td>\n",
       "      <td>None</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Jaane Bhi Do Yaaro</td>\n",
       "      <td>None</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Vada Chennai</td>\n",
       "      <td>None</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Aparajito</td>\n",
       "      <td>None</td>\n",
       "      <td>1956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Sardar Udham</td>\n",
       "      <td>None</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Khosla Ka Ghosla!</td>\n",
       "      <td>None</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Anniyan</td>\n",
       "      <td>None</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ratsasan</td>\n",
       "      <td>None</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Chupke Chupke</td>\n",
       "      <td>None</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gangs of Wasseypur</td>\n",
       "      <td>None</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Drishyam</td>\n",
       "      <td>None</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Peranbu</td>\n",
       "      <td>None</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Bangalore Days</td>\n",
       "      <td>None</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Mahanati</td>\n",
       "      <td>None</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Satya</td>\n",
       "      <td>None</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Premam</td>\n",
       "      <td>None</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name Rating  Year\n",
       "0   Ramayana: The Legend of Prince Rama   None  1993\n",
       "1            Rocketry: The Nambi Effect   None  2022\n",
       "2                               Nayakan   None  1987\n",
       "3                              Gol Maal   None  1979\n",
       "4                           777 Charlie   None  2022\n",
       "5                            Anbe Sivam   None  2003\n",
       "6                     Pariyerum Perumal   None  2018\n",
       "7                              Jai Bhim   None  2021\n",
       "8                           Apur Sansar   None  1959\n",
       "9                              3 Idiots   None  2009\n",
       "10                     Manichitrathazhu   None  1993\n",
       "11                                #Home   None  2021\n",
       "12                      Soorarai Pottru   None  2020\n",
       "13                         Black Friday   None  2004\n",
       "14                    Kumbalangi Nights   None  2019\n",
       "15                    C/o Kancharapalem   None  2018\n",
       "16                     Taare Zameen Par   None  2007\n",
       "17                             Kireedam   None  1989\n",
       "18                               Dangal   None  2016\n",
       "19                               Kaithi   None  2019\n",
       "20                               Jersey   None  2019\n",
       "21                                   96   None  2018\n",
       "22                          Maya Bazaar   None  1957\n",
       "23                            Natsamrat   None  2016\n",
       "24                           Drishyam 2   None  2021\n",
       "25                               Asuran   None  2019\n",
       "26                           Sita Ramam   None  2022\n",
       "27                         Thevar Magan   None  1992\n",
       "28                           Visaaranai   None  2015\n",
       "29                  Sarpatta Parambarai   None  2021\n",
       "30                           Thalapathi   None  1991\n",
       "31                         Nadodikkattu   None  1987\n",
       "32                      Pather Panchali   None  1955\n",
       "33                             Drishyam   None  2013\n",
       "34                         Thani Oruvan   None  2015\n",
       "35                   Jaane Bhi Do Yaaro   None  1983\n",
       "36                         Vada Chennai   None  2018\n",
       "37                            Aparajito   None  1956\n",
       "38                         Sardar Udham   None  2021\n",
       "39                    Khosla Ka Ghosla!   None  2006\n",
       "40                              Anniyan   None  2005\n",
       "41                             Ratsasan   None  2018\n",
       "42                        Chupke Chupke   None  1975\n",
       "43                   Gangs of Wasseypur   None  2012\n",
       "44                             Drishyam   None  2015\n",
       "45                              Peranbu   None  2018\n",
       "46                       Bangalore Days   None  2014\n",
       "47                             Mahanati   None  2018\n",
       "48                                Satya   None  1998\n",
       "49                               Premam   None  2015"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL to scrape IMDB's Top Rated 50 Indian movies\n",
    "url = 'https://www.imdb.com/india/top-rated-indian-movies/'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "movie_data = soup.select('td.titleColumn')\n",
    "\n",
    "# Initialize lists to store movie data\n",
    "names = []\n",
    "ratings = []\n",
    "years = []\n",
    "\n",
    "for movie in movie_data:\n",
    "    name = movie.a.text\n",
    "    rating = movie.strong\n",
    "    year = movie.span.text.strip('()')\n",
    "    names.append(name)\n",
    "    ratings.append(rating)\n",
    "    years.append(year)\n",
    "\n",
    "movie_dict = {'Name': names, 'Rating': ratings, 'Year': years}\n",
    "\n",
    "movie_df = pd.DataFrame(movie_dict)\n",
    "\n",
    "movie_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abca40a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Term of Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Term of Office]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer no.4\n",
    "\n",
    "url = 'https://presidentofindia.nic.in/former-presidents.htm'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "names = []\n",
    "terms = []\n",
    "\n",
    "for president in soup.find_all('div.col-md-9 ul li'):\n",
    "    name = president.strong.text\n",
    "    term = president.span.text\n",
    "    names.append(name)\n",
    "    terms.append(term)\n",
    "\n",
    "president_dict = {'Name': names, 'Term of Office': terms}\n",
    "\n",
    "president_df = pd.DataFrame(president_dict)\n",
    "\n",
    "president_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2956a614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Teams:\n",
      "    Pos           Team T  Matches M  Points P  Rating R\n",
      "0    1    Australia AUS         35      3965       113\n",
      "1    2        India IND         47      5294       113\n",
      "2    3   New Zealand NZ         30      3367       112\n",
      "3    4      England ENG         36      3988       111\n",
      "4    5     Pakistan PAK         25      2649       106\n",
      "5    6  South Africa SA         29      2919       101\n",
      "6    7   Bangladesh BAN         38      3625        95\n",
      "7    8     Sri Lanka SL         35      3037        87\n",
      "8    9   West Indies WI         43      3105        72\n",
      "9   10  Afghanistan AFG         20      1419        71\n",
      "\n",
      "Top 10 ODI Batsmen:\n",
      "        Pos                 Player Team  Rating             Career Best Rating\n",
      "0   1  (0)             Babar Azam  PAK     887  898 v West Indies, 10/06/2022\n",
      "1   2  (0)  Rassie van der Dussen   SA     777      796 v England, 19/07/2022\n",
      "2   3  (0)            Imam-ul-Haq  PAK     740  815 v West Indies, 12/06/2022\n",
      "3   =  (0)        Quinton de Kock   SA     740    813 v Sri Lanka, 10/03/2019\n",
      "4   5  (0)           Shubman Gill  IND     738    738 v Australia, 22/03/2023\n",
      "5   6  (0)           David Warner  AUS     726     880 v Pakistan, 26/01/2017\n",
      "6   7  (0)            Virat Kohli  IND     719      911 v England, 12/07/2018\n",
      "7   8  (0)           Rohit Sharma  IND     707    885 v Sri Lanka, 06/07/2019\n",
      "8   9  (0)            Steve Smith  AUS     702     752 v Pakistan, 22/01/2017\n",
      "9  10  (0)           Fakhar Zaman  PAK     699      779 v England, 08/07/2021\n",
      "\n",
      "Top 10 ODI Bowlers:\n",
      "        Pos            Player Team  Rating             Career Best Rating\n",
      "0   1  (0)    Josh Hazlewood  AUS     705      733 v England, 26/01/2018\n",
      "1   2  (0)       Trent Boult   NZ     701    775 v Australia, 11/09/2022\n",
      "2   3  (0)    Mohammed Siraj  IND     691  736 v New Zealand, 21/01/2023\n",
      "3   4  (0)    Mitchell Starc  AUS     686  783 v New Zealand, 29/03/2015\n",
      "4   5  (0)       Rashid Khan  AFG     659     806 v Pakistan, 21/09/2018\n",
      "5   6  (0)        Adam Zampa  AUS     652      655 v England, 22/11/2022\n",
      "6   7  (0)    Shaheen Afridi  PAK     641  688 v West Indies, 10/06/2022\n",
      "7   8  (0)  Mujeeb Ur Rahman  AFG     637      712 v Ireland, 24/01/2021\n",
      "8   9  (0)   Shakib Al Hasan  BAN     636     717 v Zimbabwe, 05/11/2009\n",
      "9  10  (0)        Matt Henry   NZ     635   691 v Bangladesh, 26/03/2021\n"
     ]
    }
   ],
   "source": [
    "# Top 10 ODI Teams\n",
    "url_teams = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "res = requests.get(url_teams)\n",
    "soup = BeautifulSoup(res.text,'html.parser')\n",
    "table = soup.find_all('table')[0]\n",
    "df_teams = pd.read_html(str(table))[0]\n",
    "df_teams = df_teams.head(10)\n",
    "\n",
    "# Top 10 ODI Batsmen\n",
    "url_batsmen = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "res = requests.get(url_batsmen)\n",
    "soup = BeautifulSoup(res.text,'html.parser')\n",
    "table = soup.find_all('table')[0]\n",
    "df_batsmen = pd.read_html(str(table))[0]\n",
    "df_batsmen = df_batsmen.head(10)\n",
    "\n",
    "# Top 10 ODI Bowlers\n",
    "url_bowlers = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "res = requests.get(url_bowlers)\n",
    "soup = BeautifulSoup(res.text,'html.parser')\n",
    "table = soup.find_all('table')[0]\n",
    "df_bowlers = pd.read_html(str(table))[0]\n",
    "df_bowlers = df_bowlers.head(10)\n",
    "\n",
    "\n",
    "\n",
    "# Print the dataframes\n",
    "print(\"Top 10 ODI Teams:\\n\", df_teams)\n",
    "print(\"\\nTop 10 ODI Batsmen:\\n\", df_batsmen)\n",
    "print(\"\\nTop 10 ODI Bowlers:\\n\", df_bowlers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4487994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Teams in Women's Cricket:\n",
      "    Pos           Team T  Matches M  Points P  Rating R\n",
      "0    1    Australia AUS         21      3603       172\n",
      "1    2      England ENG         28      3342       119\n",
      "2    3  South Africa SA         26      3098       119\n",
      "3    4        India IND         27      2820       104\n",
      "4    5   New Zealand NZ         25      2553       102\n",
      "5    6   West Indies WI         27      2535        94\n",
      "6    7   Bangladesh BAN         13       983        76\n",
      "7    8     Thailand THA          8       572        72\n",
      "8    9     Pakistan PAK         27      1678        62\n",
      "9   10     Sri Lanka SL          8       353        44\n",
      "\n",
      "Top 10 Women's ODI Batswomen:\n",
      "                                                  Pos               Player  \\\n",
      "0                                             1  (0)         Alyssa Healy   \n",
      "1                                             2  (0)          Beth Mooney   \n",
      "2                                             3  (0)      Laura Wolvaardt   \n",
      "3                                             4  (0)       Natalie Sciver   \n",
      "4  5  (2) This player has moved up in the ranking...          Meg Lanning   \n",
      "5  6  (1) This player has moved down in the ranki...     Harmanpreet Kaur   \n",
      "6  7  (1) This player has moved down in the ranki...      Smriti Mandhana   \n",
      "7                                             8  (0)       Rachael Haynes   \n",
      "8                                             9  (0)  Chamari Athapaththu   \n",
      "9                                            10  (0)    Amy Satterthwaite   \n",
      "\n",
      "  Team  Rating              Career Best Rating  \n",
      "0  AUS     762       785 v England, 03/04/2022  \n",
      "1  AUS     754      754 v Pakistan, 21/01/2023  \n",
      "2   SA     732     741 v Australia, 22/03/2022  \n",
      "3  ENG     731  755 v South Africa, 15/07/2022  \n",
      "4  AUS     717   834 v New Zealand, 24/02/2016  \n",
      "5  IND     716       731 v England, 21/09/2022  \n",
      "6  IND     714       797 v England, 28/02/2019  \n",
      "7  AUS     680   713 v West Indies, 15/03/2022  \n",
      "8   SL     655  691 v South Africa, 14/02/2019  \n",
      "9   NZ     641     756 v Australia, 02/03/2017  \n",
      "\n",
      "Top 10 Women's ODI All-rounders:\n",
      "        Pos            Player Team  Rating              Career Best Rating\n",
      "0   1  (0)   Hayley Matthews   WI     373       383 v England, 04/12/2022\n",
      "1   2  (0)    Natalie Sciver  ENG     371  395 v South Africa, 11/07/2022\n",
      "2   3  (0)      Ellyse Perry  AUS     366   548 v West Indies, 11/09/2019\n",
      "3   4  (0)    Marizanne Kapp   SA     349   419 v West Indies, 10/09/2021\n",
      "4   5  (0)       Amelia Kerr   NZ     336   356 v West Indies, 25/09/2022\n",
      "5   6  (0)     Deepti Sharma  IND     322  397 v South Africa, 09/10/2019\n",
      "6   7  (0)  Ashleigh Gardner  AUS     292      292 v Pakistan, 21/01/2023\n",
      "7   8  (0)     Jess Jonassen  AUS     250   308 v West Indies, 11/09/2019\n",
      "8   9  (0)          Nida Dar  PAK     232     232 v Australia, 21/01/2023\n",
      "9  10  (0)    Jhulan Goswami  IND     214     308 v Australia, 02/02/2016\n"
     ]
    }
   ],
   "source": [
    "# Top 10 ODI Teams in Women's Cricket\n",
    "url_teams = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "res = requests.get(url_teams)\n",
    "soup = BeautifulSoup(res.text,'html.parser')\n",
    "table = soup.find_all('table')[0]\n",
    "df_teams = pd.read_html(str(table))[0]\n",
    "df_teams = df_teams.head(10)\n",
    "\n",
    "# Top 10 Women's ODI Batswomen\n",
    "url_batswomen = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "res = requests.get(url_batswomen)\n",
    "soup = BeautifulSoup(res.text,'html.parser')\n",
    "table = soup.find_all('table')[0]\n",
    "df_batswomen = pd.read_html(str(table))[0]\n",
    "df_batswomen = df_batswomen.head(10)\n",
    "\n",
    "# Top 10 Women's ODI All-rounders\n",
    "url_allrounders = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "res = requests.get(url_allrounders)\n",
    "soup = BeautifulSoup(res.text,'html.parser')\n",
    "table = soup.find_all('table')[0]\n",
    "df_allrounders = pd.read_html(str(table))[0]\n",
    "df_allrounders = df_allrounders.head(10)\n",
    "\n",
    "# Print the dataframes\n",
    "print(\"Top 10 ODI Teams in Women's Cricket:\\n\", df_teams)\n",
    "print(\"\\nTop 10 Women's ODI Batswomen:\\n\", df_batswomen)\n",
    "print(\"\\nTop 10 Women's ODI All-rounders:\\n\", df_allrounders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffb5b12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stocks close higher Friday, Nasdaq notches bes...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/03/30/stock-market-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biden tells Russia to release WSJ reporter; Wi...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/03/31/russia-ukraine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kyiv says nearly 500 children have died in Mos...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/03/30/ukraine-war-li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'It's not a pretty picture': Russia's support ...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/03/30/ukraine-war-ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mercenary boss says Bakhmut is battering both ...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/03/29/ukraine-war-li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>German and British tanks arrive in Ukraine; Ru...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/03/28/ukraine-war-li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EU agrees to ramp up 2030 renewable energy tar...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/03/30/climate-eu-agr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Climate change is first and foremost a food se...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/video/2023/03/30/climate-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Private jet flights in Europe soar to record l...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/03/30/private-jet-fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Energy agency chief warns transition to renewa...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/03/28/renewables-ene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Here's what you need to know about Europe's 'g...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/03/24/climate-a-gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Millions will start losing Medicaid coverage a...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/03/31/medicaid-milli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>U.S. appeals decision striking down free Obama...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/03/31/obamacare-bide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Texas judge strikes down Obamacare coverage of...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/03/30/obamacare-judg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Two court cases in Washington state and Texas ...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/03/29/abortion-pill-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FDA approves over-the-counter sales of opioid ...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/03/29/opioids-fda-ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Asia's 'best restaurants' list is out — and it...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/03/29/best-restauran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Finland gives away free trips to travelers who...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/03/22/finland-gives-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Traveling to Asia for work? This city is its m...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/03/22/hong-kong-reta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>To escape the rat race, this pair cycled from ...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/03/21/cycling-from-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Here are the world's best airports for 2023</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/03/16/best-airport-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Gen Zer, millennial pay under $700/month to re...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/04/01/millennials-mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>If you use these 13 phrases every day, you hav...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/04/01/if-you-use-the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>We pay under $700/month to live in 'micro apar...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/video/2023/04/01/we-pay-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>79% of hotel guests say you should tip—but onl...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/04/01/how-much-to-ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30-day money challenge to get smarter and more...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/04/01/financial-lite...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline  Time  \\\n",
       "0   Stocks close higher Friday, Nasdaq notches bes...  None   \n",
       "1   Biden tells Russia to release WSJ reporter; Wi...  None   \n",
       "2   Kyiv says nearly 500 children have died in Mos...  None   \n",
       "3   'It's not a pretty picture': Russia's support ...  None   \n",
       "4   Mercenary boss says Bakhmut is battering both ...  None   \n",
       "5   German and British tanks arrive in Ukraine; Ru...  None   \n",
       "6   EU agrees to ramp up 2030 renewable energy tar...  None   \n",
       "7   Climate change is first and foremost a food se...  None   \n",
       "8   Private jet flights in Europe soar to record l...  None   \n",
       "9   Energy agency chief warns transition to renewa...  None   \n",
       "10  Here's what you need to know about Europe's 'g...  None   \n",
       "11  Millions will start losing Medicaid coverage a...  None   \n",
       "12  U.S. appeals decision striking down free Obama...  None   \n",
       "13  Texas judge strikes down Obamacare coverage of...  None   \n",
       "14  Two court cases in Washington state and Texas ...  None   \n",
       "15  FDA approves over-the-counter sales of opioid ...  None   \n",
       "16  Asia's 'best restaurants' list is out — and it...  None   \n",
       "17  Finland gives away free trips to travelers who...  None   \n",
       "18  Traveling to Asia for work? This city is its m...  None   \n",
       "19  To escape the rat race, this pair cycled from ...  None   \n",
       "20        Here are the world's best airports for 2023  None   \n",
       "21  Gen Zer, millennial pay under $700/month to re...  None   \n",
       "22  If you use these 13 phrases every day, you hav...  None   \n",
       "23  We pay under $700/month to live in 'micro apar...  None   \n",
       "24  79% of hotel guests say you should tip—but onl...  None   \n",
       "25  30-day money challenge to get smarter and more...  None   \n",
       "\n",
       "                                            News Link  \n",
       "0   https://www.cnbc.com/2023/03/30/stock-market-t...  \n",
       "1   https://www.cnbc.com/2023/03/31/russia-ukraine...  \n",
       "2   https://www.cnbc.com/2023/03/30/ukraine-war-li...  \n",
       "3   https://www.cnbc.com/2023/03/30/ukraine-war-ho...  \n",
       "4   https://www.cnbc.com/2023/03/29/ukraine-war-li...  \n",
       "5   https://www.cnbc.com/2023/03/28/ukraine-war-li...  \n",
       "6   https://www.cnbc.com/2023/03/30/climate-eu-agr...  \n",
       "7   https://www.cnbc.com/video/2023/03/30/climate-...  \n",
       "8   https://www.cnbc.com/2023/03/30/private-jet-fl...  \n",
       "9   https://www.cnbc.com/2023/03/28/renewables-ene...  \n",
       "10  https://www.cnbc.com/2023/03/24/climate-a-gree...  \n",
       "11  https://www.cnbc.com/2023/03/31/medicaid-milli...  \n",
       "12  https://www.cnbc.com/2023/03/31/obamacare-bide...  \n",
       "13  https://www.cnbc.com/2023/03/30/obamacare-judg...  \n",
       "14  https://www.cnbc.com/2023/03/29/abortion-pill-...  \n",
       "15  https://www.cnbc.com/2023/03/29/opioids-fda-ap...  \n",
       "16  https://www.cnbc.com/2023/03/29/best-restauran...  \n",
       "17  https://www.cnbc.com/2023/03/22/finland-gives-...  \n",
       "18  https://www.cnbc.com/2023/03/22/hong-kong-reta...  \n",
       "19  https://www.cnbc.com/2023/03/21/cycling-from-e...  \n",
       "20  https://www.cnbc.com/2023/03/16/best-airport-i...  \n",
       "21  https://www.cnbc.com/2023/04/01/millennials-mi...  \n",
       "22  https://www.cnbc.com/2023/04/01/if-you-use-the...  \n",
       "23  https://www.cnbc.com/video/2023/04/01/we-pay-u...  \n",
       "24  https://www.cnbc.com/2023/04/01/how-much-to-ti...  \n",
       "25  https://www.cnbc.com/2023/04/01/financial-lite...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.cnbc.com/world/?region=world\"\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "news_list = soup.find_all('div', class_='Card-titleContainer')\n",
    "headlines = []\n",
    "times = []\n",
    "links = []\n",
    "\n",
    "for news in news_list:\n",
    "    headline = news.find('a', class_='Card-title').text.strip()\n",
    "    time = news.find('time', class_='Card-title')\n",
    "    link = news.find('a', class_='Card-title')['href']\n",
    "    headlines.append(headline)\n",
    "    times.append(time)\n",
    "    links.append(link)\n",
    "\n",
    "df = pd.DataFrame({'Headline': headlines, 'Time': times, 'News Link': links})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65158a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Paper Title, Authors, Published Date, Paper URL]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\"\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "articles = soup.find_all('div', class_='pod-listing-header')\n",
    "\n",
    "titles = []\n",
    "authors = []\n",
    "dates = []\n",
    "urls = []\n",
    "\n",
    "for article in articles:\n",
    "    title = article.find('a', class_='pod-listing-title-link').text.strip()\n",
    "    author = article.find('div', class_='pod-listing-authors').text.strip()\n",
    "    date = article.find('div', class_='pod-listing-details').text.strip()\n",
    "    url = article.find('a', class_='pod-listing-title-link')['href']\n",
    "    titles.append(title)\n",
    "    authors.append(author)\n",
    "    dates.append(date)\n",
    "    urls.append(url)\n",
    "\n",
    "df = pd.DataFrame({'Paper Title': titles, 'Authors': authors, 'Published Date': dates, 'Paper URL': urls})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27db0e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Restaurant Name Cuisine Location Ratings Image URL\n",
       "0                                                   \n",
       "1                                                   \n",
       "2                                                   \n",
       "3                                                   \n",
       "4                                                   \n",
       "5                                                   \n",
       "6                                                   \n",
       "7                                                   \n",
       "8                                                   "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.dineout.co.in/delhi-restaurants/buffet-special\"\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "restaurants = soup.find_all('div', class_='restnt-info')\n",
    "names = []\n",
    "cuisines = []\n",
    "locations = []\n",
    "ratings = []\n",
    "image_urls = []\n",
    "\n",
    "for restaurant in restaurants:\n",
    "    try:\n",
    "        name = restaurant.find('h2', class_='restnt-name').text.strip()\n",
    "    except:\n",
    "        name = \"\"\n",
    "    try:\n",
    "        cuisine = restaurant.find('p', class_='restnt-cuisine').text.strip()\n",
    "    except:\n",
    "        cuisine = \"\"\n",
    "    try:\n",
    "        location = restaurant.find('p', class_='restnt-loc').text.strip()\n",
    "    except:\n",
    "        location = \"\"\n",
    "    try:\n",
    "        rating = restaurant.find('div', class_='restnt-rating').text.strip()\n",
    "    except:\n",
    "        rating = \"\"\n",
    "    try:\n",
    "        image_url = restaurant.find('img', class_='restnt-img')['data-src']\n",
    "    except:\n",
    "        image_url = \"\"\n",
    "    names.append(name)\n",
    "    cuisines.append(cuisine)\n",
    "    locations.append(location)\n",
    "    ratings.append(rating)\n",
    "    image_urls.append(image_url)\n",
    "\n",
    "df = pd.DataFrame({'Restaurant Name': names, 'Cuisine': cuisines, 'Location': locations, 'Ratings': ratings, 'Image URL': image_urls})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dff700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
